{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Reviews csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of reviews is: 189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>months_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We love The Old Phoenix - this is the fourth t...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a disappointment. We have wanted to stay ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We walked over to Fenix from Loutro and stayed...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Old Phoenix was the low point of our two w...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had a fantastic time at Old-Phoenix!\\nThe be...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  months_ago\n",
       "0  We love The Old Phoenix - this is the fourth t...      5           5\n",
       "1  What a disappointment. We have wanted to stay ...      1           4\n",
       "2  We walked over to Fenix from Loutro and stayed...      5           6\n",
       "3  The Old Phoenix was the low point of our two w...      1           5\n",
       "4  I had a fantastic time at Old-Phoenix!\\nThe be...      5           7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_dir = 'c:\\\\Users\\\\DanaTal\\\\projects\\\\nlp\\\\Bridezilla_NLP'\n",
    "os.path.exists(home_dir)\n",
    "data_dir = os.path.join(home_dir, f'data')\n",
    "data_path = glob(data_dir + '\\\\*.csv')[0]\n",
    "data_path\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f' number of reviews is: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used this article for the summerization task: \n",
    "\n",
    "https://medium.com/@sarowar.saurav10/6-useful-text-summarization-algorithm-in-python-dfc8a9d33074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df: pd.DataFrame, tokenizer, model, config: dict) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    for i, row in df.iterrows():\n",
    "        sequence = row.text\n",
    "        input = tokenizer.encode(\"summarize: \" + sequence, return_tensors='pt', max_length=config['max_input_length'], truncation=config['trunc_input'])\n",
    "        output = model.generate(input, max_length=config['max_output_length'], min_length=config['min_output_length'], length_penalty=config['length_penalty'], num_beams=config['num_beams'])\n",
    "        summary = tokenizer.decode(output[0])\n",
    "        # remove tresh from the str\n",
    "        df.at[i, \"summary\"] = summary.split(\">\")[1].split(\"<\")[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5 imports\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenizer & model\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model =  T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n",
    "\n",
    "# I chose this hypper parameters for the model\n",
    "T5_config = {'max_input_length':1024, 'trunc_input':True, 'max_output_length':100, 'min_output_length':1, 'length_penalty':5, 'num_beams':2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>months_ago</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We love The Old Phoenix - this is the fourth t...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>this is the fourth time we’ve visited the old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a disappointment. We have wanted to stay ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>we have wanted to stay here for years but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We walked over to Fenix from Loutro and stayed...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>we walked over to stony beach from Loutro and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Old Phoenix was the low point of our two w...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>the old Phoenix was the low point of our two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had a fantastic time at Old-Phoenix!\\nThe be...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>the beautiful beach on site provided the perfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Very beautiful!</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>very beautiful!..................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Flawless</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>flawless &amp; snn &amp; snn &amp; snn &amp; snn &amp; snn &amp; snn &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Everything is great!!</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>everything is great!!! everything is great!!!....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Amazing place</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>Amazing place....................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Magical place.</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Magical place - the world's most beautiful pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  stars  months_ago  \\\n",
       "0    We love The Old Phoenix - this is the fourth t...      5           5   \n",
       "1    What a disappointment. We have wanted to stay ...      1           4   \n",
       "2    We walked over to Fenix from Loutro and stayed...      5           6   \n",
       "3    The Old Phoenix was the low point of our two w...      1           5   \n",
       "4    I had a fantastic time at Old-Phoenix!\\nThe be...      5           7   \n",
       "..                                                 ...    ...         ...   \n",
       "184                                    Very beautiful!      5          24   \n",
       "185                                           Flawless      5          48   \n",
       "186                              Everything is great!!      5          36   \n",
       "187                                      Amazing place      5         120   \n",
       "188                                     Magical place.      5          36   \n",
       "\n",
       "                                               summary  \n",
       "0     this is the fourth time we’ve visited the old...  \n",
       "1     we have wanted to stay here for years but it ...  \n",
       "2     we walked over to stony beach from Loutro and...  \n",
       "3     the old Phoenix was the low point of our two ...  \n",
       "4    the beautiful beach on site provided the perfe...  \n",
       "..                                                 ...  \n",
       "184  very beautiful!..................................  \n",
       "185  flawless & snn & snn & snn & snn & snn & snn &...  \n",
       "186  everything is great!!! everything is great!!!....  \n",
       "187  Amazing place....................................  \n",
       "188  Magical place - the world's most beautiful pla...  \n",
       "\n",
       "[189 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer T5 model \n",
    "summarize(df, tokenizer, model, T5_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output\n",
    "summariztion_output_dir = os.path.join(home_dir, f\"outputs\\\\summarization\")\n",
    "os.makedirs(summariztion_output_dirb, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summariztion_output_path = os.path.join(summariztion_output_dir, f'{model_name}.csv')\n",
    "df.to_csv(summariztion_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BART Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "model_name = \"ainize/bart-base-cnn\"\n",
    "#  Load Model and Tokenize\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_config = {'max_input_length':1024, 'trunc_input':True, 'max_output_length':100, 'min_output_length':1, 'length_penalty':5, 'num_beams':2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of reviews is: 189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>months_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We love The Old Phoenix - this is the fourth t...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a disappointment. We have wanted to stay ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We walked over to Fenix from Loutro and stayed...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Old Phoenix was the low point of our two w...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had a fantastic time at Old-Phoenix!\\nThe be...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  months_ago\n",
       "0  We love The Old Phoenix - this is the fourth t...      5           5\n",
       "1  What a disappointment. We have wanted to stay ...      1           4\n",
       "2  We walked over to Fenix from Loutro and stayed...      5           6\n",
       "3  The Old Phoenix was the low point of our two w...      1           5\n",
       "4  I had a fantastic time at Old-Phoenix!\\nThe be...      5           7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "print(f' number of reviews is: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    sequence = row.text\n",
    "    input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "    # Generate Summary Text Ids\n",
    "    summary_tokens = model.generate(\n",
    "        input_ids=input,\n",
    "        bos_token_id=model.config.bos_token_id,\n",
    "        eos_token_id=model.config.eos_token_id,\n",
    "        length_penalty=2.0,\n",
    "        max_length=100,\n",
    "        min_length=1,\n",
    "        num_beams=4,\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_tokens[0], skip_special_tokens=True)\n",
    "    df.at[i, \"summary\"] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "summariztion_output_path = os.path.join(summariztion_output_dir, f'base-bart.csv')\n",
    "df.to_csv(summariztion_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating summarization of texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Evaluate using bert score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Old Phoenix is secluded and quiet, and the swimming in the bay is sublime.\\nIf you’re expecting five-star luxury, go somewhere else; this is a traditional …'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = df.summary[0]\n",
    "references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "hypotheses = [df.text[0]]\n",
    "references = [df.summary[0]]\n",
    "results= bertscore.compute(predictions=hypotheses, references=references,  model_type=\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.88301682472229], 'recall': [0.9785053133964539], 'f1': [0.9283120036125183], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.35.2)'}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Evaluate using ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\danatal\\anaconda3\\envs\\dana\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "To be able to use evaluate-metric/rouge, you need to install the following dependencies['absl', 'rouge_score'] using 'pip install # Here to have a nice missing dependency error message early on rouge_score' for instance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DanaTal\\projects\\nlp\\Bridezilla_NLP\\summarize\\summarize.ipynb Cell 29\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DanaTal/projects/nlp/Bridezilla_NLP/summarize/summarize.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevaluate\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DanaTal/projects/nlp/Bridezilla_NLP/summarize/summarize.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Loading the 'rouge' metric from the library\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DanaTal/projects/nlp/Bridezilla_NLP/summarize/summarize.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rouge \u001b[39m=\u001b[39m load(\u001b[39m'\u001b[39;49m\u001b[39mrouge\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\DanaTal\\anaconda3\\envs\\dana\\Lib\\site-packages\\evaluate\\loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[39m=\u001b[39m DownloadMode(download_mode \u001b[39mor\u001b[39;00m DownloadMode\u001b[39m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[1;32m--> 748\u001b[0m evaluation_module \u001b[39m=\u001b[39m evaluation_module_factory(\n\u001b[0;32m    749\u001b[0m     path, module_type\u001b[39m=\u001b[39;49mmodule_type, revision\u001b[39m=\u001b[39;49mrevision, download_config\u001b[39m=\u001b[39;49mdownload_config, download_mode\u001b[39m=\u001b[39;49mdownload_mode\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    751\u001b[0m evaluation_cls \u001b[39m=\u001b[39m import_main_class(evaluation_module\u001b[39m.\u001b[39mmodule_path)\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[39m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[39m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[39m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DanaTal\\anaconda3\\envs\\dana\\Lib\\site-packages\\evaluate\\loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    679\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, (\u001b[39mConnectionError\u001b[39;00m, \u001b[39mFileNotFoundError\u001b[39;00m)):\n\u001b[1;32m--> 680\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    682\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a module script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    683\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist on the Hugging Face Hub either.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    684\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\DanaTal\\anaconda3\\envs\\dana\\Lib\\site-packages\\evaluate\\loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mfor\u001b[39;00m current_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcomparison\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmeasurement\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    632\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    633\u001b[0m         \u001b[39mreturn\u001b[39;00m HubEvaluationModuleFactory(\n\u001b[0;32m    634\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mevaluate-\u001b[39;49m\u001b[39m{\u001b[39;49;00mcurrent_type\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    635\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    636\u001b[0m             download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m    637\u001b[0m             download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m    638\u001b[0m             dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[1;32m--> 639\u001b[0m         )\u001b[39m.\u001b[39;49mget_module()\n\u001b[0;32m    640\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DanaTal\\anaconda3\\envs\\dana\\Lib\\site-packages\\evaluate\\loading.py:489\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    488\u001b[0m imports \u001b[39m=\u001b[39m get_imports(local_path)\n\u001b[1;32m--> 489\u001b[0m local_imports \u001b[39m=\u001b[39m _download_additional_modules(\n\u001b[0;32m    490\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    491\u001b[0m     base_path\u001b[39m=\u001b[39;49mhf_hub_url(path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, revision\u001b[39m=\u001b[39;49mrevision),\n\u001b[0;32m    492\u001b[0m     imports\u001b[39m=\u001b[39;49mimports,\n\u001b[0;32m    493\u001b[0m     download_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config,\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    495\u001b[0m \u001b[39m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[0;32m    496\u001b[0m dynamic_modules_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39melse\u001b[39;00m init_dynamic_modules()\n",
      "File \u001b[1;32mc:\\Users\\DanaTal\\anaconda3\\envs\\dana\\Lib\\site-packages\\evaluate\\loading.py:265\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[1;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[0;32m    263\u001b[0m         needs_to_be_installed\u001b[39m.\u001b[39madd((library_import_name, library_import_path))\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m needs_to_be_installed:\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    266\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTo be able to use \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m, you need to install the following dependencies\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m[lib_name\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlib_name,\u001b[39m \u001b[39mlib_path\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mneeds_to_be_installed]\u001b[39m}\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lib_path\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlib_name,\u001b[39m \u001b[39mlib_path\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mneeds_to_be_installed])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for instance\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m     )\n\u001b[0;32m    270\u001b[0m \u001b[39mreturn\u001b[39;00m local_imports\n",
      "\u001b[1;31mImportError\u001b[0m: To be able to use evaluate-metric/rouge, you need to install the following dependencies['absl', 'rouge_score'] using 'pip install # Here to have a nice missing dependency error message early on rouge_score' for instance'"
     ]
    }
   ],
   "source": [
    "# Import the load function from the evaluate module\n",
    "from evaluate import load\n",
    "\n",
    "# Loading the 'rouge' metric from the library\n",
    "rouge = load('rouge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'r': 1.0, 'p': 0.6486486486486487, 'f': 0.7868852411287289}, 'rouge-2': {'r': 0.9259259259259259, 'p': 0.5952380952380952, 'f': 0.7246376763957153}, 'rouge-l': {'r': 1.0, 'p': 0.6486486486486487, 'f': 0.7868852411287289}}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from rouge import Rouge\n",
    "\n",
    "# Define the generated summary and the reference summary\n",
    "generated_summary = df.text[0]\n",
    "reference_summary = df.summary[0]\n",
    "# Initialize the ROUGE object\n",
    "rouge = Rouge()\n",
    "# Calculate ROUGE for the generated and reference summaries\n",
    "scores = rouge.get_scores(generated_summary, reference_summary)\n",
    "# Print the results\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install absl-py rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.763157894736842, 'rouge2': 0.7027027027027025, 'rougeL': 0.763157894736842, 'rougeLsum': 0.763157894736842}\n"
     ]
    }
   ],
   "source": [
    "# Import the load function from the evaluate module\n",
    "from evaluate import load\n",
    "\n",
    "# Loading the 'rouge' metric from the library\n",
    "rouge = load('rouge')\n",
    "\n",
    "# Define your predictions and references\n",
    "predictions = [df.text[0]]\n",
    "references = [df.summary[0]]\n",
    "\n",
    "# Compute the scores\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print the scores\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.763157894736842,\n",
       " 'rouge2': 0.7027027027027025,\n",
       " 'rougeL': 0.763157894736842,\n",
       " 'rougeLsum': 0.763157894736842}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_df(pred, reference, model):\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rouge-1', 'rouge-2', 'rouge-l'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluete models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DanaTal\\\\projects\\\\nlp\\\\Bridezilla_NLP\\\\outputs\\\\summarization'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summariztion_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DanaTal\\\\projects\\\\nlp\\\\Bridezilla_NLP\\\\outputs\\\\summarization\\\\t5-small.csv'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_path = glob(summariztion_output_dir + '\\\\*bart*.csv')[0]\n",
    "t5_path = glob(summariztion_output_dir + '\\\\*t5*.csv')[0]\n",
    "t5_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = pd.read_csv(bart_path)\n",
    "t5 = pd.read_csv(t5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "evaluate_df = deepcopy(bart)\n",
    "evaluate_df = evaluate_df.rename(columns={\"summary\": \"bart\"}).reset_index(drop=True)\n",
    "evaluate_df = pd.concat([evaluate_df, t5[\"summary\"]], axis=1).reset_index(drop=True)\n",
    "evaluate_df = evaluate_df.rename(columns={\"summary\": \"t5\"}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>months_ago</th>\n",
       "      <th>bart</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We love The Old Phoenix - this is the fourth t...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The Old Phoenix is secluded and quiet, and the...</td>\n",
       "      <td>this is the fourth time we’ve visited the old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a disappointment. We have wanted to stay ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>We have wanted to stay here for years but it w...</td>\n",
       "      <td>we have wanted to stay here for years but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We walked over to Fenix from Loutro and stayed...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>We walked over to Fenix from Loutro and stayed...</td>\n",
       "      <td>we walked over to stony beach from Loutro and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Old Phoenix was the low point of our two w...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Old Phoenix was the low point of our two w...</td>\n",
       "      <td>the old Phoenix was the low point of our two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had a fantastic time at Old-Phoenix!\\nThe be...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>\"The beautiful beach on site provided the perf...</td>\n",
       "      <td>the beautiful beach on site provided the perfe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  months_ago  \\\n",
       "0  We love The Old Phoenix - this is the fourth t...      5           5   \n",
       "1  What a disappointment. We have wanted to stay ...      1           4   \n",
       "2  We walked over to Fenix from Loutro and stayed...      5           6   \n",
       "3  The Old Phoenix was the low point of our two w...      1           5   \n",
       "4  I had a fantastic time at Old-Phoenix!\\nThe be...      5           7   \n",
       "\n",
       "                                                bart  \\\n",
       "0  The Old Phoenix is secluded and quiet, and the...   \n",
       "1  We have wanted to stay here for years but it w...   \n",
       "2  We walked over to Fenix from Loutro and stayed...   \n",
       "3  The Old Phoenix was the low point of our two w...   \n",
       "4  \"The beautiful beach on site provided the perf...   \n",
       "\n",
       "                                                  t5  \n",
       "0   this is the fourth time we’ve visited the old...  \n",
       "1   we have wanted to stay here for years but it ...  \n",
       "2   we walked over to stony beach from Loutro and...  \n",
       "3   the old Phoenix was the low point of our two ...  \n",
       "4  the beautiful beach on site provided the perfe...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
